{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Reproducing the Experiment in \"Prediction of Pedestrian Speed with Artificial Neural Networks\" by Tordeux et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Enable these if automatic reloading of modules is wanted\n",
    "\n",
    "# Load extension for automatic reload of modules\n",
    "%load_ext autoreload\n",
    "# Enable autoreload for all modules\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import inspect\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import tensorboard\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import preprocessing\n",
    "import plotting\n",
    "import pedestrian_dataset\n",
    "import pedestrian_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tensorboard\n",
    "\n",
    "Extension for visualizing the training results.\n",
    "Should only be loaded once, otherwise there is probably an error message.\n",
    "\n",
    "To start, run `tensorboard --logdir=dir --port 6006` in a terminal or run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-307ad89ccb1b56ca\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-307ad89ccb1b56ca\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs --port 6009"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Logging\n",
    "\n",
    "I used Logging to print messages.\n",
    "If more messages are welcome, use the logging level `logging.INFO` or even `logging.DEBUG`.\n",
    "If not, use `logging.WARNING`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set Logging Level\n",
    "logger_format = '%(levelname)s - %(funcName)s \\t%(message)s'\n",
    "logger_level = logging.WARNING\n",
    "logging.basicConfig(level=logger_level, format=logger_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1887efbeb70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a torch seed\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing and Loading the Dataset\n",
    "\n",
    "The different files of data in the format\n",
    "(`PedID FrameID X Y Z`)\n",
    "are loaded and converted into the following dictionary format:\n",
    "\n",
    "`distances` | `speeds`\n",
    "-|-\n",
    "Input of our neural network. Array of size $2k+1$ containing the median speed of the $k$ nearest neighbors as the first element and the relative $x$- and $y$-positions of the $k$ nearest neighbors in the following pattern afterwards: $x_1$, $y_1$, $x_2$, $y_2$, ... | Truth value for our neural network. The speed that the pedestrian had in that frame.\n",
    "\n",
    "To load a list of files, the method `pedestrian_dataset.create_dataset()` is used.\n",
    "As its first parameter it either takes a list of data files that it should load\n",
    "or a `pedestrian_dataset.PedestrianDataType` value,\n",
    "which can be either `BOTTLENECK`, which loads all bottleneck files,\n",
    "`CORRIDOR`, which loads all corridor files,\n",
    "or `ALL`, which loads all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'distances': array([ 296.80893951,   36.1585    ,  -91.69      ,   76.8931    ,\n",
      "         62.0273    ,   -2.372     ,  201.1667    ,  -21.5438    ,\n",
      "       -241.436     ,   29.8531    , -262.229     ,   32.8202    ,\n",
      "        295.624     ,  -18.6053    ,  316.108     ,  -26.2509    ,\n",
      "        437.719     ,   43.2941    ,  445.954     ,   -0.6295    ,\n",
      "        559.384     ]), 'speed': 6.112364455756874}\n"
     ]
    }
   ],
   "source": [
    "# Creating datasets with only the smallest corridor scenario with 30 participants\n",
    "c_015_path = \"./Data/Corridor_Data/ug-180-030.txt\"\n",
    "# Note: even when only loading one dataset, it has to be given in a list\n",
    "c_015_train_val_datasets, c_015_test_dataset = pedestrian_dataset.create_dataset([c_015_path])\n",
    "\n",
    "# Print the first item from the first train/val dataset part\n",
    "print(c_015_train_val_datasets[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# Create a PyTorch dataloader with the dataset\n",
    "\n",
    "# TODO: I don't know how to do cross validation, so we combine the first 4 train/val datasets\n",
    "#   to build the train dataset and use the last train/val dataset as the val dataset\n",
    "#   Maybe we just have to do this everytime (and switch it up)? Could be, but not sure\n",
    "c_015_temp_train_dataset = torch.utils.data.ConcatDataset(c_015_train_val_datasets[:4])\n",
    "c_015_temp_val_dataset = c_015_train_val_datasets[4]\n",
    "\n",
    "c_015_train_loader = DataLoader(c_015_temp_train_dataset, batch_size=batch_size, drop_last=True)\n",
    "c_015_val_loader = DataLoader(c_015_temp_train_dataset, batch_size=batch_size, drop_last=False)\n",
    "\n",
    "c_015_test_loader = DataLoader(c_015_test_dataset, batch_size=batch_size, drop_last=False)\n",
    "\n",
    "# # Print the first value given by the train loader\n",
    "# for item in c_015_train_loader:\n",
    "#     print(item)\n",
    "#     break  # break after printing the first item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'distances': array([ 83.28914988, -32.428     ,  24.169     ,  37.9846    ,\n",
      "        38.714     ,  -2.5528    , -57.585     ,   4.0326    ,\n",
      "        69.008     ,  81.5544    ,   6.506     , -71.6767    ,\n",
      "       -54.426     ,  49.6994    , -84.303     , -57.71222   ,\n",
      "        80.09      ,  86.0264    , -55.428     ,  80.5664    ,\n",
      "        75.733     ]), 'speed': 2.5783409394414765}\n"
     ]
    }
   ],
   "source": [
    "# Creating datasets with all scenarios loaded\n",
    "all_train_val_datasets, all_test_dataset = pedestrian_dataset.create_dataset(\n",
    "    pedestrian_dataset.PedestrianDataType.ALL\n",
    ")\n",
    "\n",
    "# Print the first item from the first train/val dataset part\n",
    "print(all_train_val_datasets[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "\n",
    "# Create a PyTorch dataloader with the dataset\n",
    "\n",
    "# TODO: I don't know how to do cross validation, so we combine the first 4 train/val datasets\n",
    "#   to build the train dataset and use the last train/val dataset as the val dataset\n",
    "#   Maybe we just have to do this everytime (and switch it up)? Could be, but not sure\n",
    "all_temp_train_dataset = torch.utils.data.ConcatDataset(all_train_val_datasets[:4])\n",
    "all_temp_val_dataset = all_train_val_datasets[4]\n",
    "\n",
    "all_train_loader = DataLoader(all_temp_train_dataset, batch_size=batch_size, drop_last=True)\n",
    "all_val_loader = DataLoader(all_temp_train_dataset, batch_size=batch_size, drop_last=False)\n",
    "\n",
    "all_test_loader = DataLoader(all_test_dataset, batch_size=batch_size, drop_last=False)\n",
    "\n",
    "# # Currently Disabled because for batch_size=16 this get's large\n",
    "# # Print the first value given by the train loader\n",
    "# for item in all_train_loader:\n",
    "#     print(item)\n",
    "#     break  # break after printing the first item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create normalized DataLoaders\n",
    "\n",
    "normalized_train_loader = DataLoader(preprocessing.normalize_data(all_temp_train_dataset), batch_size=batch_size, drop_last=True)\n",
    "normalized_val_loader = DataLoader(preprocessing.normalize_data(all_temp_val_dataset), batch_size=batch_size, drop_last=True)\n",
    "normalized_test_loader = DataLoader(preprocessing.normalize_data(all_test_dataset), batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing and Training the Model\n",
    "\n",
    "Now we need to define our model.\n",
    "\n",
    "@Parim:\n",
    "I got quite a lot of work done on the model, but there are still TODOs.\n",
    "I probably won't be able to work more on the practicum this week, but I think everything should be documented well enough to be extended by you.\n",
    "(I'm using PyTorch Lightning now, which you'll probably remember from I2DL, and the Neural Network is in `pedestrian_net.py`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_name = \"./.name/checkpoints/2023-07-05--dataAll-ep100-it001.ckpt\"\n",
    "\n",
    "max_epochs = 50\n",
    "k = 10\n",
    "hidden_size = 3\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available.\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CPU will be used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Choose our dataloaders\n",
    "# train_loader = all_train_loader\n",
    "# val_loader   = all_val_loader\n",
    "# test_loader  = all_test_loader\n",
    "\n",
    "train_loader = normalized_train_loader\n",
    "val_loader = normalized_val_loader\n",
    "test_loader = normalized_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define an early stopping callback\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", mode='min', patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PedestrianNet(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=21, out_features=3, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=3, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define our model\n",
    "model = pedestrian_net.PedestrianNet(k=k,\n",
    "                                     hidden_size=hidden_size,\n",
    "                                     learning_rate=learning_rate,\n",
    "                                     optimizer=optimizer\n",
    "                                     )\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    devices='auto',\n",
    "    accelerator='gpu',\n",
    "    callbacks=[early_stop_callback],\n",
    "    log_every_n_steps=1,\n",
    "    enable_checkpointing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 70    \n",
      "-------------------------------------\n",
      "70        Trainable params\n",
      "0         Non-trainable params\n",
      "70        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|                                                              | 0/2 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sukap\\anaconda3\\envs\\i2dl\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sukap\\anaconda3\\envs\\i2dl\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  81%|█████████████████████▊     | 42/52 [00:05<00:01,  7.22it/s, loss=0.0267, v_num=2, train_loss_step=0.0278]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  83%|██████████████████████▎    | 43/52 [00:06<00:01,  7.13it/s, loss=0.0267, v_num=2, train_loss_step=0.0278]\u001b[A\n",
      "Epoch 0:  85%|██████████████████████▊    | 44/52 [00:06<00:01,  7.23it/s, loss=0.0267, v_num=2, train_loss_step=0.0278]\u001b[A\n",
      "Epoch 0:  87%|███████████████████████▎   | 45/52 [00:06<00:00,  7.34it/s, loss=0.0267, v_num=2, train_loss_step=0.0278]\u001b[A\n",
      "Epoch 0:  88%|███████████████████████▉   | 46/52 [00:06<00:00,  7.45it/s, loss=0.0267, v_num=2, train_loss_step=0.0278]\u001b[A\n",
      "Epoch 0:  90%|████████████████████████▍  | 47/52 [00:06<00:00,  7.55it/s, loss=0.0267, v_num=2, train_loss_step=0.0278]\u001b[A\n",
      "Epoch 0:  92%|████████████████████████▉  | 48/52 [00:06<00:00,  7.65it/s, loss=0.0267, v_num=2, train_loss_step=0.0278]\u001b[A\n",
      "Epoch 0:  94%|█████████████████████████▍ | 49/52 [00:06<00:00,  7.74it/s, loss=0.0267, v_num=2, train_loss_step=0.0278]\u001b[A\n",
      "Epoch 0:  96%|█████████████████████████▉ | 50/52 [00:06<00:00,  7.84it/s, loss=0.0267, v_num=2, train_loss_step=0.0278]\u001b[A\n",
      "Epoch 0:  98%|██████████████████████████▍| 51/52 [00:06<00:00,  7.94it/s, loss=0.0267, v_num=2, train_loss_step=0.0278]\u001b[A\n",
      "Epoch 0: 100%|█| 52/52 [00:06<00:00,  8.02it/s, loss=0.0267, v_num=2, train_loss_step=0.0278, val_loss_step=0.028, val_\u001b[A\n",
      "Epoch 1:  81%|▊| 42/52 [00:08<00:02,  4.70it/s, loss=0.0227, v_num=2, train_loss_step=0.0241, val_loss_step=0.028, val_\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  83%|▊| 43/52 [00:08<00:01,  4.78it/s, loss=0.0227, v_num=2, train_loss_step=0.0241, val_loss_step=0.028, val_\u001b[A\n",
      "Epoch 1:  85%|▊| 44/52 [00:09<00:01,  4.87it/s, loss=0.0227, v_num=2, train_loss_step=0.0241, val_loss_step=0.028, val_\u001b[A\n",
      "Epoch 1:  87%|▊| 45/52 [00:09<00:01,  4.95it/s, loss=0.0227, v_num=2, train_loss_step=0.0241, val_loss_step=0.028, val_\u001b[A\n",
      "Epoch 1:  88%|▉| 46/52 [00:09<00:01,  5.04it/s, loss=0.0227, v_num=2, train_loss_step=0.0241, val_loss_step=0.028, val_\u001b[A\n",
      "Epoch 1:  90%|▉| 47/52 [00:09<00:00,  5.12it/s, loss=0.0227, v_num=2, train_loss_step=0.0241, val_loss_step=0.028, val_\u001b[A\n",
      "Epoch 1:  92%|▉| 48/52 [00:09<00:00,  5.20it/s, loss=0.0227, v_num=2, train_loss_step=0.0241, val_loss_step=0.028, val_\u001b[A\n",
      "Epoch 1:  94%|▉| 49/52 [00:09<00:00,  5.28it/s, loss=0.0227, v_num=2, train_loss_step=0.0241, val_loss_step=0.028, val_\u001b[A\n",
      "Epoch 1:  96%|▉| 50/52 [00:09<00:00,  5.36it/s, loss=0.0227, v_num=2, train_loss_step=0.0241, val_loss_step=0.028, val_\u001b[A\n",
      "Epoch 1:  98%|▉| 51/52 [00:09<00:00,  5.44it/s, loss=0.0227, v_num=2, train_loss_step=0.0241, val_loss_step=0.028, val_\u001b[A\n",
      "Epoch 1: 100%|█| 52/52 [00:09<00:00,  5.42it/s, loss=0.0227, v_num=2, train_loss_step=0.0241, val_loss_step=0.0243, val\u001b[A\n",
      "Epoch 2:  81%|▊| 42/52 [00:12<00:02,  3.48it/s, loss=0.0213, v_num=2, train_loss_step=0.0231, val_loss_step=0.0243, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  83%|▊| 43/52 [00:12<00:02,  3.55it/s, loss=0.0213, v_num=2, train_loss_step=0.0231, val_loss_step=0.0243, val\u001b[A\n",
      "Epoch 2:  85%|▊| 44/52 [00:12<00:02,  3.60it/s, loss=0.0213, v_num=2, train_loss_step=0.0231, val_loss_step=0.0243, val\u001b[A\n",
      "Epoch 2:  87%|▊| 45/52 [00:12<00:01,  3.67it/s, loss=0.0213, v_num=2, train_loss_step=0.0231, val_loss_step=0.0243, val\u001b[A\n",
      "Epoch 2:  88%|▉| 46/52 [00:12<00:01,  3.74it/s, loss=0.0213, v_num=2, train_loss_step=0.0231, val_loss_step=0.0243, val\u001b[A\n",
      "Epoch 2:  90%|▉| 47/52 [00:12<00:01,  3.80it/s, loss=0.0213, v_num=2, train_loss_step=0.0231, val_loss_step=0.0243, val\u001b[A\n",
      "Epoch 2:  92%|▉| 48/52 [00:12<00:01,  3.87it/s, loss=0.0213, v_num=2, train_loss_step=0.0231, val_loss_step=0.0243, val\u001b[A\n",
      "Epoch 2:  94%|▉| 49/52 [00:12<00:00,  3.94it/s, loss=0.0213, v_num=2, train_loss_step=0.0231, val_loss_step=0.0243, val\u001b[A\n",
      "Epoch 2:  96%|▉| 50/52 [00:12<00:00,  4.00it/s, loss=0.0213, v_num=2, train_loss_step=0.0231, val_loss_step=0.0243, val\u001b[A\n",
      "Epoch 2:  98%|▉| 51/52 [00:12<00:00,  4.07it/s, loss=0.0213, v_num=2, train_loss_step=0.0231, val_loss_step=0.0243, val\u001b[A\n",
      "Epoch 2: 100%|█| 52/52 [00:12<00:00,  4.12it/s, loss=0.0213, v_num=2, train_loss_step=0.0231, val_loss_step=0.0232, val\u001b[A\n",
      "Epoch 3:  81%|▊| 42/52 [00:15<00:03,  2.79it/s, loss=0.0205, v_num=2, train_loss_step=0.0224, val_loss_step=0.0232, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  83%|▊| 43/52 [00:15<00:03,  2.84it/s, loss=0.0205, v_num=2, train_loss_step=0.0224, val_loss_step=0.0232, val\u001b[A\n",
      "Epoch 3:  85%|▊| 44/52 [00:15<00:02,  2.90it/s, loss=0.0205, v_num=2, train_loss_step=0.0224, val_loss_step=0.0232, val\u001b[A\n",
      "Epoch 3:  87%|▊| 45/52 [00:15<00:02,  2.96it/s, loss=0.0205, v_num=2, train_loss_step=0.0224, val_loss_step=0.0232, val\u001b[A\n",
      "Epoch 3:  88%|▉| 46/52 [00:15<00:01,  3.01it/s, loss=0.0205, v_num=2, train_loss_step=0.0224, val_loss_step=0.0232, val\u001b[A\n",
      "Epoch 3:  90%|▉| 47/52 [00:15<00:01,  3.04it/s, loss=0.0205, v_num=2, train_loss_step=0.0224, val_loss_step=0.0232, val\u001b[A\n",
      "Epoch 3:  92%|▉| 48/52 [00:15<00:01,  3.09it/s, loss=0.0205, v_num=2, train_loss_step=0.0224, val_loss_step=0.0232, val\u001b[A\n",
      "Epoch 3:  94%|▉| 49/52 [00:15<00:00,  3.15it/s, loss=0.0205, v_num=2, train_loss_step=0.0224, val_loss_step=0.0232, val\u001b[A\n",
      "Epoch 3:  96%|▉| 50/52 [00:15<00:00,  3.20it/s, loss=0.0205, v_num=2, train_loss_step=0.0224, val_loss_step=0.0232, val\u001b[A\n",
      "Epoch 3:  98%|▉| 51/52 [00:15<00:00,  3.26it/s, loss=0.0205, v_num=2, train_loss_step=0.0224, val_loss_step=0.0232, val\u001b[A\n",
      "Epoch 3: 100%|█| 52/52 [00:15<00:00,  3.31it/s, loss=0.0205, v_num=2, train_loss_step=0.0224, val_loss_step=0.0225, val\u001b[A\n",
      "Epoch 4:  81%|▊| 42/52 [00:18<00:04,  2.31it/s, loss=0.0199, v_num=2, train_loss_step=0.022, val_loss_step=0.0225, val_\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  83%|▊| 43/52 [00:18<00:03,  2.36it/s, loss=0.0199, v_num=2, train_loss_step=0.022, val_loss_step=0.0225, val_\u001b[A\n",
      "Epoch 4:  85%|▊| 44/52 [00:18<00:03,  2.41it/s, loss=0.0199, v_num=2, train_loss_step=0.022, val_loss_step=0.0225, val_\u001b[A\n",
      "Epoch 4:  87%|▊| 45/52 [00:18<00:02,  2.45it/s, loss=0.0199, v_num=2, train_loss_step=0.022, val_loss_step=0.0225, val_\u001b[A\n",
      "Epoch 4:  88%|▉| 46/52 [00:18<00:02,  2.50it/s, loss=0.0199, v_num=2, train_loss_step=0.022, val_loss_step=0.0225, val_\u001b[A\n",
      "Epoch 4:  90%|▉| 47/52 [00:18<00:01,  2.55it/s, loss=0.0199, v_num=2, train_loss_step=0.022, val_loss_step=0.0225, val_\u001b[A\n",
      "Epoch 4:  92%|▉| 48/52 [00:18<00:01,  2.60it/s, loss=0.0199, v_num=2, train_loss_step=0.022, val_loss_step=0.0225, val_\u001b[A\n",
      "Epoch 4:  94%|▉| 49/52 [00:18<00:01,  2.65it/s, loss=0.0199, v_num=2, train_loss_step=0.022, val_loss_step=0.0225, val_\u001b[A\n",
      "Epoch 4:  96%|▉| 50/52 [00:18<00:00,  2.69it/s, loss=0.0199, v_num=2, train_loss_step=0.022, val_loss_step=0.0225, val_\u001b[A\n",
      "Epoch 4:  98%|▉| 51/52 [00:18<00:00,  2.74it/s, loss=0.0199, v_num=2, train_loss_step=0.022, val_loss_step=0.0225, val_\u001b[A\n",
      "Epoch 4: 100%|█| 52/52 [00:18<00:00,  2.78it/s, loss=0.0199, v_num=2, train_loss_step=0.022, val_loss_step=0.0221, val_\u001b[A\n",
      "Epoch 5:  81%|▊| 42/52 [00:21<00:05,  1.97it/s, loss=0.0195, v_num=2, train_loss_step=0.0217, val_loss_step=0.0221, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  83%|▊| 43/52 [00:21<00:04,  2.01it/s, loss=0.0195, v_num=2, train_loss_step=0.0217, val_loss_step=0.0221, val\u001b[A\n",
      "Epoch 5:  85%|▊| 44/52 [00:21<00:03,  2.05it/s, loss=0.0195, v_num=2, train_loss_step=0.0217, val_loss_step=0.0221, val\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  87%|▊| 45/52 [00:21<00:03,  2.10it/s, loss=0.0195, v_num=2, train_loss_step=0.0217, val_loss_step=0.0221, val\u001b[A\n",
      "Epoch 5:  88%|▉| 46/52 [00:21<00:02,  2.14it/s, loss=0.0195, v_num=2, train_loss_step=0.0217, val_loss_step=0.0221, val\u001b[A\n",
      "Epoch 5:  90%|▉| 47/52 [00:21<00:02,  2.18it/s, loss=0.0195, v_num=2, train_loss_step=0.0217, val_loss_step=0.0221, val\u001b[A\n",
      "Epoch 5:  92%|▉| 48/52 [00:21<00:01,  2.22it/s, loss=0.0195, v_num=2, train_loss_step=0.0217, val_loss_step=0.0221, val\u001b[A\n",
      "Epoch 5:  94%|▉| 49/52 [00:21<00:01,  2.26it/s, loss=0.0195, v_num=2, train_loss_step=0.0217, val_loss_step=0.0221, val\u001b[A\n",
      "Epoch 5:  96%|▉| 50/52 [00:21<00:00,  2.30it/s, loss=0.0195, v_num=2, train_loss_step=0.0217, val_loss_step=0.0221, val\u001b[A\n",
      "Epoch 5:  98%|▉| 51/52 [00:21<00:00,  2.34it/s, loss=0.0195, v_num=2, train_loss_step=0.0217, val_loss_step=0.0221, val\u001b[A\n",
      "Epoch 5: 100%|█| 52/52 [00:21<00:00,  2.38it/s, loss=0.0195, v_num=2, train_loss_step=0.0217, val_loss_step=0.0218, val\u001b[A\n",
      "Epoch 6:  81%|▊| 42/52 [00:24<00:05,  1.73it/s, loss=0.0191, v_num=2, train_loss_step=0.0214, val_loss_step=0.0218, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  83%|▊| 43/52 [00:24<00:05,  1.77it/s, loss=0.0191, v_num=2, train_loss_step=0.0214, val_loss_step=0.0218, val\u001b[A\n",
      "Epoch 6:  85%|▊| 44/52 [00:24<00:04,  1.80it/s, loss=0.0191, v_num=2, train_loss_step=0.0214, val_loss_step=0.0218, val\u001b[A\n",
      "Epoch 6:  87%|▊| 45/52 [00:24<00:03,  1.84it/s, loss=0.0191, v_num=2, train_loss_step=0.0214, val_loss_step=0.0218, val\u001b[A\n",
      "Epoch 6:  88%|▉| 46/52 [00:24<00:03,  1.88it/s, loss=0.0191, v_num=2, train_loss_step=0.0214, val_loss_step=0.0218, val\u001b[A\n",
      "Epoch 6:  90%|▉| 47/52 [00:24<00:02,  1.91it/s, loss=0.0191, v_num=2, train_loss_step=0.0214, val_loss_step=0.0218, val\u001b[A\n",
      "Epoch 6:  92%|▉| 48/52 [00:24<00:02,  1.95it/s, loss=0.0191, v_num=2, train_loss_step=0.0214, val_loss_step=0.0218, val\u001b[A\n",
      "Epoch 6:  94%|▉| 49/52 [00:24<00:01,  1.99it/s, loss=0.0191, v_num=2, train_loss_step=0.0214, val_loss_step=0.0218, val\u001b[A\n",
      "Epoch 6:  96%|▉| 50/52 [00:24<00:00,  2.02it/s, loss=0.0191, v_num=2, train_loss_step=0.0214, val_loss_step=0.0218, val\u001b[A\n",
      "Epoch 6:  98%|▉| 51/52 [00:24<00:00,  2.05it/s, loss=0.0191, v_num=2, train_loss_step=0.0214, val_loss_step=0.0218, val\u001b[A\n",
      "Epoch 6: 100%|█| 52/52 [00:24<00:00,  2.08it/s, loss=0.0191, v_num=2, train_loss_step=0.0214, val_loss_step=0.0216, val\u001b[A\n",
      "Epoch 7:  81%|▊| 42/52 [00:27<00:06,  1.53it/s, loss=0.0189, v_num=2, train_loss_step=0.0212, val_loss_step=0.0216, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  83%|▊| 43/52 [00:27<00:05,  1.56it/s, loss=0.0189, v_num=2, train_loss_step=0.0212, val_loss_step=0.0216, val\u001b[A\n",
      "Epoch 7:  85%|▊| 44/52 [00:27<00:05,  1.60it/s, loss=0.0189, v_num=2, train_loss_step=0.0212, val_loss_step=0.0216, val\u001b[A\n",
      "Epoch 7:  87%|▊| 45/52 [00:27<00:04,  1.63it/s, loss=0.0189, v_num=2, train_loss_step=0.0212, val_loss_step=0.0216, val\u001b[A\n",
      "Epoch 7:  88%|▉| 46/52 [00:27<00:03,  1.66it/s, loss=0.0189, v_num=2, train_loss_step=0.0212, val_loss_step=0.0216, val\u001b[A\n",
      "Epoch 7:  90%|▉| 47/52 [00:27<00:02,  1.70it/s, loss=0.0189, v_num=2, train_loss_step=0.0212, val_loss_step=0.0216, val\u001b[A\n",
      "Epoch 7:  92%|▉| 48/52 [00:27<00:02,  1.73it/s, loss=0.0189, v_num=2, train_loss_step=0.0212, val_loss_step=0.0216, val\u001b[A\n",
      "Epoch 7:  94%|▉| 49/52 [00:27<00:01,  1.76it/s, loss=0.0189, v_num=2, train_loss_step=0.0212, val_loss_step=0.0216, val\u001b[A\n",
      "Epoch 7:  96%|▉| 50/52 [00:27<00:01,  1.80it/s, loss=0.0189, v_num=2, train_loss_step=0.0212, val_loss_step=0.0216, val\u001b[A\n",
      "Epoch 7:  98%|▉| 51/52 [00:27<00:00,  1.83it/s, loss=0.0189, v_num=2, train_loss_step=0.0212, val_loss_step=0.0216, val\u001b[A\n",
      "Epoch 7: 100%|█| 52/52 [00:27<00:00,  1.86it/s, loss=0.0189, v_num=2, train_loss_step=0.0212, val_loss_step=0.0214, val\u001b[A\n",
      "Epoch 8:  81%|▊| 42/52 [00:30<00:07,  1.38it/s, loss=0.0187, v_num=2, train_loss_step=0.021, val_loss_step=0.0214, val_\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  83%|▊| 43/52 [00:30<00:06,  1.41it/s, loss=0.0187, v_num=2, train_loss_step=0.021, val_loss_step=0.0214, val_\u001b[A\n",
      "Epoch 8:  85%|▊| 44/52 [00:30<00:05,  1.44it/s, loss=0.0187, v_num=2, train_loss_step=0.021, val_loss_step=0.0214, val_\u001b[A\n",
      "Epoch 8:  87%|▊| 45/52 [00:30<00:04,  1.47it/s, loss=0.0187, v_num=2, train_loss_step=0.021, val_loss_step=0.0214, val_\u001b[A\n",
      "Epoch 8:  88%|▉| 46/52 [00:30<00:04,  1.49it/s, loss=0.0187, v_num=2, train_loss_step=0.021, val_loss_step=0.0214, val_\u001b[A\n",
      "Epoch 8:  90%|▉| 47/52 [00:30<00:03,  1.52it/s, loss=0.0187, v_num=2, train_loss_step=0.021, val_loss_step=0.0214, val_\u001b[A\n",
      "Epoch 8:  92%|▉| 48/52 [00:30<00:02,  1.55it/s, loss=0.0187, v_num=2, train_loss_step=0.021, val_loss_step=0.0214, val_\u001b[A\n",
      "Epoch 8:  94%|▉| 49/52 [00:30<00:01,  1.58it/s, loss=0.0187, v_num=2, train_loss_step=0.021, val_loss_step=0.0214, val_\u001b[A\n",
      "Epoch 8:  96%|▉| 50/52 [00:30<00:01,  1.61it/s, loss=0.0187, v_num=2, train_loss_step=0.021, val_loss_step=0.0214, val_\u001b[A\n",
      "Epoch 8:  98%|▉| 51/52 [00:31<00:00,  1.64it/s, loss=0.0187, v_num=2, train_loss_step=0.021, val_loss_step=0.0214, val_\u001b[A\n",
      "Epoch 8: 100%|█| 52/52 [00:31<00:00,  1.67it/s, loss=0.0187, v_num=2, train_loss_step=0.021, val_loss_step=0.0212, val_\u001b[A\n",
      "Epoch 9:  81%|▊| 42/52 [00:33<00:07,  1.25it/s, loss=0.0185, v_num=2, train_loss_step=0.0209, val_loss_step=0.0212, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  83%|▊| 43/52 [00:33<00:07,  1.28it/s, loss=0.0185, v_num=2, train_loss_step=0.0209, val_loss_step=0.0212, val\u001b[A\n",
      "Epoch 9:  85%|▊| 44/52 [00:33<00:06,  1.31it/s, loss=0.0185, v_num=2, train_loss_step=0.0209, val_loss_step=0.0212, val\u001b[A\n",
      "Epoch 9:  87%|▊| 45/52 [00:33<00:05,  1.34it/s, loss=0.0185, v_num=2, train_loss_step=0.0209, val_loss_step=0.0212, val\u001b[A\n",
      "Epoch 9:  88%|▉| 46/52 [00:33<00:04,  1.37it/s, loss=0.0185, v_num=2, train_loss_step=0.0209, val_loss_step=0.0212, val\u001b[A\n",
      "Epoch 9:  90%|▉| 47/52 [00:33<00:03,  1.39it/s, loss=0.0185, v_num=2, train_loss_step=0.0209, val_loss_step=0.0212, val\u001b[A\n",
      "Epoch 9:  92%|▉| 48/52 [00:33<00:02,  1.42it/s, loss=0.0185, v_num=2, train_loss_step=0.0209, val_loss_step=0.0212, val\u001b[A\n",
      "Epoch 9:  94%|▉| 49/52 [00:33<00:02,  1.45it/s, loss=0.0185, v_num=2, train_loss_step=0.0209, val_loss_step=0.0212, val\u001b[A\n",
      "Epoch 9:  96%|▉| 50/52 [00:33<00:01,  1.48it/s, loss=0.0185, v_num=2, train_loss_step=0.0209, val_loss_step=0.0212, val\u001b[A\n",
      "Epoch 9:  98%|▉| 51/52 [00:33<00:00,  1.50it/s, loss=0.0185, v_num=2, train_loss_step=0.0209, val_loss_step=0.0212, val\u001b[A\n",
      "Epoch 9: 100%|█| 52/52 [00:33<00:00,  1.53it/s, loss=0.0185, v_num=2, train_loss_step=0.0209, val_loss_step=0.0211, val\u001b[A\n",
      "Epoch 10:  81%|▊| 42/52 [00:36<00:08,  1.15it/s, loss=0.0184, v_num=2, train_loss_step=0.0207, val_loss_step=0.0211, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  83%|▊| 43/52 [00:36<00:07,  1.18it/s, loss=0.0184, v_num=2, train_loss_step=0.0207, val_loss_step=0.0211, va\u001b[A\n",
      "Epoch 10:  85%|▊| 44/52 [00:36<00:06,  1.20it/s, loss=0.0184, v_num=2, train_loss_step=0.0207, val_loss_step=0.0211, va\u001b[A\n",
      "Epoch 10:  87%|▊| 45/52 [00:36<00:05,  1.22it/s, loss=0.0184, v_num=2, train_loss_step=0.0207, val_loss_step=0.0211, va\u001b[A\n",
      "Epoch 10:  88%|▉| 46/52 [00:36<00:04,  1.25it/s, loss=0.0184, v_num=2, train_loss_step=0.0207, val_loss_step=0.0211, va\u001b[A\n",
      "Epoch 10:  90%|▉| 47/52 [00:36<00:03,  1.28it/s, loss=0.0184, v_num=2, train_loss_step=0.0207, val_loss_step=0.0211, va\u001b[A\n",
      "Epoch 10:  92%|▉| 48/52 [00:36<00:03,  1.30it/s, loss=0.0184, v_num=2, train_loss_step=0.0207, val_loss_step=0.0211, va\u001b[A\n",
      "Epoch 10:  94%|▉| 49/52 [00:36<00:02,  1.33it/s, loss=0.0184, v_num=2, train_loss_step=0.0207, val_loss_step=0.0211, va\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  96%|▉| 50/52 [00:36<00:01,  1.35it/s, loss=0.0184, v_num=2, train_loss_step=0.0207, val_loss_step=0.0211, va\u001b[A\n",
      "Epoch 10:  98%|▉| 51/52 [00:37<00:00,  1.38it/s, loss=0.0184, v_num=2, train_loss_step=0.0207, val_loss_step=0.0211, va\u001b[A\n",
      "Epoch 10: 100%|█| 52/52 [00:37<00:00,  1.40it/s, loss=0.0184, v_num=2, train_loss_step=0.0207, val_loss_step=0.0209, va\u001b[A\n",
      "Epoch 11:  81%|▊| 42/52 [00:39<00:09,  1.06it/s, loss=0.0182, v_num=2, train_loss_step=0.0206, val_loss_step=0.0209, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  83%|▊| 43/52 [00:39<00:08,  1.09it/s, loss=0.0182, v_num=2, train_loss_step=0.0206, val_loss_step=0.0209, va\u001b[A\n",
      "Epoch 11:  85%|▊| 44/52 [00:39<00:07,  1.11it/s, loss=0.0182, v_num=2, train_loss_step=0.0206, val_loss_step=0.0209, va\u001b[A\n",
      "Epoch 11:  87%|▊| 45/52 [00:39<00:06,  1.13it/s, loss=0.0182, v_num=2, train_loss_step=0.0206, val_loss_step=0.0209, va\u001b[A\n",
      "Epoch 11:  88%|▉| 46/52 [00:39<00:05,  1.16it/s, loss=0.0182, v_num=2, train_loss_step=0.0206, val_loss_step=0.0209, va\u001b[A\n",
      "Epoch 11:  90%|▉| 47/52 [00:39<00:04,  1.18it/s, loss=0.0182, v_num=2, train_loss_step=0.0206, val_loss_step=0.0209, va\u001b[A\n",
      "Epoch 11:  92%|▉| 48/52 [00:39<00:03,  1.20it/s, loss=0.0182, v_num=2, train_loss_step=0.0206, val_loss_step=0.0209, va\u001b[A\n",
      "Epoch 11:  94%|▉| 49/52 [00:39<00:02,  1.23it/s, loss=0.0182, v_num=2, train_loss_step=0.0206, val_loss_step=0.0209, va\u001b[A\n",
      "Epoch 11:  96%|▉| 50/52 [00:40<00:01,  1.25it/s, loss=0.0182, v_num=2, train_loss_step=0.0206, val_loss_step=0.0209, va\u001b[A\n",
      "Epoch 11:  98%|▉| 51/52 [00:40<00:00,  1.27it/s, loss=0.0182, v_num=2, train_loss_step=0.0206, val_loss_step=0.0209, va\u001b[A\n",
      "Epoch 11: 100%|█| 52/52 [00:40<00:00,  1.29it/s, loss=0.0182, v_num=2, train_loss_step=0.0206, val_loss_step=0.0208, va\u001b[A\n",
      "Epoch 12:  81%|▊| 42/52 [00:42<00:10,  1.02s/it, loss=0.0181, v_num=2, train_loss_step=0.0205, val_loss_step=0.0208, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  83%|▊| 43/52 [00:42<00:08,  1.00it/s, loss=0.0181, v_num=2, train_loss_step=0.0205, val_loss_step=0.0208, va\u001b[A\n",
      "Epoch 12:  85%|▊| 44/52 [00:42<00:07,  1.03it/s, loss=0.0181, v_num=2, train_loss_step=0.0205, val_loss_step=0.0208, va\u001b[A\n",
      "Epoch 12:  87%|▊| 45/52 [00:42<00:06,  1.05it/s, loss=0.0181, v_num=2, train_loss_step=0.0205, val_loss_step=0.0208, va\u001b[A\n",
      "Epoch 12:  88%|▉| 46/52 [00:42<00:05,  1.07it/s, loss=0.0181, v_num=2, train_loss_step=0.0205, val_loss_step=0.0208, va\u001b[A\n",
      "Epoch 12:  90%|▉| 47/52 [00:42<00:04,  1.09it/s, loss=0.0181, v_num=2, train_loss_step=0.0205, val_loss_step=0.0208, va\u001b[A\n",
      "Epoch 12:  92%|▉| 48/52 [00:43<00:03,  1.12it/s, loss=0.0181, v_num=2, train_loss_step=0.0205, val_loss_step=0.0208, va\u001b[A\n",
      "Epoch 12:  94%|▉| 49/52 [00:43<00:02,  1.14it/s, loss=0.0181, v_num=2, train_loss_step=0.0205, val_loss_step=0.0208, va\u001b[A\n",
      "Epoch 12:  96%|▉| 50/52 [00:43<00:01,  1.16it/s, loss=0.0181, v_num=2, train_loss_step=0.0205, val_loss_step=0.0208, va\u001b[A\n",
      "Epoch 12:  98%|▉| 51/52 [00:43<00:00,  1.18it/s, loss=0.0181, v_num=2, train_loss_step=0.0205, val_loss_step=0.0208, va\u001b[A\n",
      "Epoch 12: 100%|█| 52/52 [00:43<00:00,  1.20it/s, loss=0.0181, v_num=2, train_loss_step=0.0205, val_loss_step=0.0207, va\u001b[A\n",
      "Epoch 13:  81%|▊| 42/52 [00:45<00:10,  1.08s/it, loss=0.018, v_num=2, train_loss_step=0.0204, val_loss_step=0.0207, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  83%|▊| 43/52 [00:45<00:09,  1.06s/it, loss=0.018, v_num=2, train_loss_step=0.0204, val_loss_step=0.0207, val\u001b[A\n",
      "Epoch 13:  85%|▊| 44/52 [00:45<00:08,  1.04s/it, loss=0.018, v_num=2, train_loss_step=0.0204, val_loss_step=0.0207, val\u001b[A\n",
      "Epoch 13:  87%|▊| 45/52 [00:45<00:07,  1.02s/it, loss=0.018, v_num=2, train_loss_step=0.0204, val_loss_step=0.0207, val\u001b[A\n",
      "Epoch 13:  88%|▉| 46/52 [00:45<00:05,  1.01it/s, loss=0.018, v_num=2, train_loss_step=0.0204, val_loss_step=0.0207, val\u001b[A\n",
      "Epoch 13:  90%|▉| 47/52 [00:45<00:04,  1.03it/s, loss=0.018, v_num=2, train_loss_step=0.0204, val_loss_step=0.0207, val\u001b[A\n",
      "Epoch 13:  92%|▉| 48/52 [00:45<00:03,  1.04it/s, loss=0.018, v_num=2, train_loss_step=0.0204, val_loss_step=0.0207, val\u001b[A\n",
      "Epoch 13:  94%|▉| 49/52 [00:46<00:02,  1.06it/s, loss=0.018, v_num=2, train_loss_step=0.0204, val_loss_step=0.0207, val\u001b[A\n",
      "Epoch 13:  96%|▉| 50/52 [00:46<00:01,  1.08it/s, loss=0.018, v_num=2, train_loss_step=0.0204, val_loss_step=0.0207, val\u001b[A\n",
      "Epoch 13:  98%|▉| 51/52 [00:46<00:00,  1.10it/s, loss=0.018, v_num=2, train_loss_step=0.0204, val_loss_step=0.0207, val\u001b[A\n",
      "Epoch 13: 100%|█| 52/52 [00:46<00:00,  1.13it/s, loss=0.018, v_num=2, train_loss_step=0.0204, val_loss_step=0.0206, val\u001b[A\n",
      "Epoch 14:  81%|▊| 42/52 [00:48<00:11,  1.16s/it, loss=0.0179, v_num=2, train_loss_step=0.0203, val_loss_step=0.0206, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  83%|▊| 43/52 [00:48<00:10,  1.13s/it, loss=0.0179, v_num=2, train_loss_step=0.0203, val_loss_step=0.0206, va\u001b[A\n",
      "Epoch 14:  85%|▊| 44/52 [00:48<00:08,  1.11s/it, loss=0.0179, v_num=2, train_loss_step=0.0203, val_loss_step=0.0206, va\u001b[A\n",
      "Epoch 14:  87%|▊| 45/52 [00:48<00:07,  1.08s/it, loss=0.0179, v_num=2, train_loss_step=0.0203, val_loss_step=0.0206, va\u001b[A\n",
      "Epoch 14:  88%|▉| 46/52 [00:48<00:06,  1.06s/it, loss=0.0179, v_num=2, train_loss_step=0.0203, val_loss_step=0.0206, va\u001b[A\n",
      "Epoch 14:  90%|▉| 47/52 [00:48<00:05,  1.04s/it, loss=0.0179, v_num=2, train_loss_step=0.0203, val_loss_step=0.0206, va\u001b[A\n",
      "Epoch 14:  92%|▉| 48/52 [00:48<00:04,  1.02s/it, loss=0.0179, v_num=2, train_loss_step=0.0203, val_loss_step=0.0206, va\u001b[A\n",
      "Epoch 14:  94%|▉| 49/52 [00:49<00:03,  1.00s/it, loss=0.0179, v_num=2, train_loss_step=0.0203, val_loss_step=0.0206, va\u001b[A\n",
      "Epoch 14:  96%|▉| 50/52 [00:49<00:01,  1.02it/s, loss=0.0179, v_num=2, train_loss_step=0.0203, val_loss_step=0.0206, va\u001b[A\n",
      "Epoch 14:  98%|▉| 51/52 [00:49<00:00,  1.04it/s, loss=0.0179, v_num=2, train_loss_step=0.0203, val_loss_step=0.0206, va\u001b[A\n",
      "Epoch 14: 100%|█| 52/52 [00:49<00:00,  1.06it/s, loss=0.0179, v_num=2, train_loss_step=0.0203, val_loss_step=0.0205, va\u001b[A\n",
      "Epoch 15:  81%|▊| 42/52 [00:51<00:12,  1.23s/it, loss=0.0178, v_num=2, train_loss_step=0.0202, val_loss_step=0.0205, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  83%|▊| 43/52 [00:51<00:10,  1.20s/it, loss=0.0178, v_num=2, train_loss_step=0.0202, val_loss_step=0.0205, va\u001b[A\n",
      "Epoch 15:  85%|▊| 44/52 [00:51<00:09,  1.18s/it, loss=0.0178, v_num=2, train_loss_step=0.0202, val_loss_step=0.0205, va\u001b[A\n",
      "Epoch 15:  87%|▊| 45/52 [00:51<00:08,  1.15s/it, loss=0.0178, v_num=2, train_loss_step=0.0202, val_loss_step=0.0205, va\u001b[A\n",
      "Epoch 15:  88%|▉| 46/52 [00:51<00:06,  1.13s/it, loss=0.0178, v_num=2, train_loss_step=0.0202, val_loss_step=0.0205, va\u001b[A\n",
      "Epoch 15:  90%|▉| 47/52 [00:52<00:05,  1.11s/it, loss=0.0178, v_num=2, train_loss_step=0.0202, val_loss_step=0.0205, va\u001b[A\n",
      "Epoch 15:  92%|▉| 48/52 [00:52<00:04,  1.08s/it, loss=0.0178, v_num=2, train_loss_step=0.0202, val_loss_step=0.0205, va\u001b[A\n",
      "Epoch 15:  94%|▉| 49/52 [00:52<00:03,  1.06s/it, loss=0.0178, v_num=2, train_loss_step=0.0202, val_loss_step=0.0205, va\u001b[A\n",
      "Epoch 15:  96%|▉| 50/52 [00:52<00:02,  1.04s/it, loss=0.0178, v_num=2, train_loss_step=0.0202, val_loss_step=0.0205, va\u001b[A\n",
      "Epoch 15:  98%|▉| 51/52 [00:52<00:01,  1.02s/it, loss=0.0178, v_num=2, train_loss_step=0.0202, val_loss_step=0.0205, va\u001b[A\n",
      "Epoch 15: 100%|█| 52/52 [00:52<00:00,  1.01s/it, loss=0.0178, v_num=2, train_loss_step=0.0202, val_loss_step=0.0204, va\u001b[A\n",
      "Epoch 16:  81%|▊| 42/52 [00:54<00:13,  1.30s/it, loss=0.0177, v_num=2, train_loss_step=0.0201, val_loss_step=0.0204, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  83%|▊| 43/52 [00:54<00:11,  1.27s/it, loss=0.0177, v_num=2, train_loss_step=0.0201, val_loss_step=0.0204, va\u001b[A\n",
      "Epoch 16:  85%|▊| 44/52 [00:54<00:09,  1.25s/it, loss=0.0177, v_num=2, train_loss_step=0.0201, val_loss_step=0.0204, va\u001b[A\n",
      "Epoch 16:  87%|▊| 45/52 [00:54<00:08,  1.22s/it, loss=0.0177, v_num=2, train_loss_step=0.0201, val_loss_step=0.0204, va\u001b[A\n",
      "Epoch 16:  88%|▉| 46/52 [00:54<00:07,  1.19s/it, loss=0.0177, v_num=2, train_loss_step=0.0201, val_loss_step=0.0204, va\u001b[A\n",
      "Epoch 16:  90%|▉| 47/52 [00:54<00:05,  1.17s/it, loss=0.0177, v_num=2, train_loss_step=0.0201, val_loss_step=0.0204, va\u001b[A\n",
      "Epoch 16:  92%|▉| 48/52 [00:55<00:04,  1.15s/it, loss=0.0177, v_num=2, train_loss_step=0.0201, val_loss_step=0.0204, va\u001b[A\n",
      "Epoch 16:  94%|▉| 49/52 [00:55<00:03,  1.12s/it, loss=0.0177, v_num=2, train_loss_step=0.0201, val_loss_step=0.0204, va\u001b[A\n",
      "Epoch 16:  96%|▉| 50/52 [00:55<00:02,  1.10s/it, loss=0.0177, v_num=2, train_loss_step=0.0201, val_loss_step=0.0204, va\u001b[A\n",
      "Epoch 16:  98%|▉| 51/52 [00:55<00:01,  1.08s/it, loss=0.0177, v_num=2, train_loss_step=0.0201, val_loss_step=0.0204, va\u001b[A\n",
      "Epoch 16: 100%|█| 52/52 [00:55<00:00,  1.07s/it, loss=0.0177, v_num=2, train_loss_step=0.0201, val_loss_step=0.0203, va\u001b[A\n",
      "Epoch 17:  81%|▊| 42/52 [00:57<00:13,  1.38s/it, loss=0.0176, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  83%|▊| 43/52 [00:57<00:12,  1.35s/it, loss=0.0176, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 17:  85%|▊| 44/52 [00:57<00:10,  1.32s/it, loss=0.0176, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 17:  87%|▊| 45/52 [00:58<00:09,  1.29s/it, loss=0.0176, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 17:  88%|▉| 46/52 [00:58<00:07,  1.26s/it, loss=0.0176, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 17:  90%|▉| 47/52 [00:58<00:06,  1.24s/it, loss=0.0176, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 17:  92%|▉| 48/52 [00:58<00:04,  1.21s/it, loss=0.0176, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 17:  94%|▉| 49/52 [00:58<00:03,  1.19s/it, loss=0.0176, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 17:  96%|▉| 50/52 [00:58<00:02,  1.17s/it, loss=0.0176, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 17:  98%|▉| 51/52 [00:58<00:01,  1.14s/it, loss=0.0176, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 17: 100%|█| 52/52 [00:58<00:00,  1.12s/it, loss=0.0176, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 18:  81%|▊| 42/52 [01:00<00:14,  1.45s/it, loss=0.0175, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  83%|▊| 43/52 [01:00<00:12,  1.42s/it, loss=0.0175, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 18:  85%|▊| 44/52 [01:00<00:11,  1.38s/it, loss=0.0175, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 18:  87%|▊| 45/52 [01:00<00:09,  1.35s/it, loss=0.0175, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 18:  88%|▉| 46/52 [01:01<00:07,  1.33s/it, loss=0.0175, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 18:  90%|▉| 47/52 [01:01<00:06,  1.30s/it, loss=0.0175, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 18:  92%|▉| 48/52 [01:01<00:05,  1.28s/it, loss=0.0175, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 18:  94%|▉| 49/52 [01:01<00:03,  1.25s/it, loss=0.0175, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 18:  96%|▉| 50/52 [01:01<00:02,  1.23s/it, loss=0.0175, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 18:  98%|▉| 51/52 [01:01<00:01,  1.20s/it, loss=0.0175, v_num=2, train_loss_step=0.020, val_loss_step=0.0203, val\u001b[A\n",
      "Epoch 18: 100%|█| 52/52 [01:01<00:00,  1.18s/it, loss=0.0175, v_num=2, train_loss_step=0.020, val_loss_step=0.0202, val\u001b[A\n",
      "Epoch 19:  81%|▊| 42/52 [01:03<00:15,  1.52s/it, loss=0.0175, v_num=2, train_loss_step=0.0199, val_loss_step=0.0202, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  83%|▊| 43/52 [01:03<00:13,  1.49s/it, loss=0.0175, v_num=2, train_loss_step=0.0199, val_loss_step=0.0202, va\u001b[A\n",
      "Epoch 19:  85%|▊| 44/52 [01:04<00:11,  1.46s/it, loss=0.0175, v_num=2, train_loss_step=0.0199, val_loss_step=0.0202, va\u001b[A\n",
      "Epoch 19:  87%|▊| 45/52 [01:04<00:09,  1.42s/it, loss=0.0175, v_num=2, train_loss_step=0.0199, val_loss_step=0.0202, va\u001b[A\n",
      "Epoch 19:  88%|▉| 46/52 [01:04<00:08,  1.39s/it, loss=0.0175, v_num=2, train_loss_step=0.0199, val_loss_step=0.0202, va\u001b[A\n",
      "Epoch 19:  90%|▉| 47/52 [01:04<00:06,  1.37s/it, loss=0.0175, v_num=2, train_loss_step=0.0199, val_loss_step=0.0202, va\u001b[A\n",
      "Epoch 19:  92%|▉| 48/52 [01:04<00:05,  1.34s/it, loss=0.0175, v_num=2, train_loss_step=0.0199, val_loss_step=0.0202, va\u001b[A\n",
      "Epoch 19:  94%|▉| 49/52 [01:04<00:03,  1.31s/it, loss=0.0175, v_num=2, train_loss_step=0.0199, val_loss_step=0.0202, va\u001b[A\n",
      "Epoch 19:  96%|▉| 50/52 [01:04<00:02,  1.29s/it, loss=0.0175, v_num=2, train_loss_step=0.0199, val_loss_step=0.0202, va\u001b[A\n",
      "Epoch 19:  98%|▉| 51/52 [01:04<00:01,  1.26s/it, loss=0.0175, v_num=2, train_loss_step=0.0199, val_loss_step=0.0202, va\u001b[A\n",
      "Epoch 19: 100%|█| 52/52 [01:04<00:00,  1.24s/it, loss=0.0175, v_num=2, train_loss_step=0.0199, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 20:  81%|▊| 42/52 [01:06<00:15,  1.59s/it, loss=0.0174, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  83%|▊| 43/52 [01:07<00:14,  1.56s/it, loss=0.0174, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 20:  85%|▊| 44/52 [01:07<00:12,  1.53s/it, loss=0.0174, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 20:  87%|▊| 45/52 [01:07<00:10,  1.49s/it, loss=0.0174, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 20:  88%|▉| 46/52 [01:07<00:08,  1.46s/it, loss=0.0174, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 20:  90%|▉| 47/52 [01:07<00:07,  1.43s/it, loss=0.0174, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 20:  92%|▉| 48/52 [01:07<00:05,  1.40s/it, loss=0.0174, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 20:  94%|▉| 49/52 [01:07<00:04,  1.38s/it, loss=0.0174, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 20:  96%|▉| 50/52 [01:07<00:02,  1.35s/it, loss=0.0174, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 20:  98%|▉| 51/52 [01:07<00:01,  1.32s/it, loss=0.0174, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 20: 100%|█| 52/52 [01:07<00:00,  1.30s/it, loss=0.0174, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 21:  81%|▊| 42/52 [01:09<00:16,  1.67s/it, loss=0.0173, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  83%|▊| 43/52 [01:10<00:14,  1.63s/it, loss=0.0173, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 21:  85%|▊| 44/52 [01:10<00:12,  1.59s/it, loss=0.0173, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 21:  87%|▊| 45/52 [01:10<00:10,  1.56s/it, loss=0.0173, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 21:  88%|▉| 46/52 [01:10<00:09,  1.53s/it, loss=0.0173, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21:  90%|▉| 47/52 [01:10<00:07,  1.49s/it, loss=0.0173, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 21:  92%|▉| 48/52 [01:10<00:05,  1.46s/it, loss=0.0173, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 21:  94%|▉| 49/52 [01:10<00:04,  1.44s/it, loss=0.0173, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 21:  96%|▉| 50/52 [01:10<00:02,  1.41s/it, loss=0.0173, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 21:  98%|▉| 51/52 [01:10<00:01,  1.38s/it, loss=0.0173, v_num=2, train_loss_step=0.0198, val_loss_step=0.0201, va\u001b[A\n",
      "Epoch 21: 100%|█| 52/52 [01:10<00:00,  1.36s/it, loss=0.0173, v_num=2, train_loss_step=0.0198, val_loss_step=0.020, val\u001b[A\n",
      "Epoch 22:  81%|▊| 42/52 [01:13<00:17,  1.74s/it, loss=0.0173, v_num=2, train_loss_step=0.0197, val_loss_step=0.020, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  83%|▊| 43/52 [01:13<00:15,  1.70s/it, loss=0.0173, v_num=2, train_loss_step=0.0197, val_loss_step=0.020, val\u001b[A\n",
      "Epoch 22:  85%|▊| 44/52 [01:13<00:13,  1.66s/it, loss=0.0173, v_num=2, train_loss_step=0.0197, val_loss_step=0.020, val\u001b[A\n",
      "Epoch 22:  87%|▊| 45/52 [01:13<00:11,  1.63s/it, loss=0.0173, v_num=2, train_loss_step=0.0197, val_loss_step=0.020, val\u001b[A\n",
      "Epoch 22:  88%|▉| 46/52 [01:13<00:09,  1.59s/it, loss=0.0173, v_num=2, train_loss_step=0.0197, val_loss_step=0.020, val\u001b[A\n",
      "Epoch 22:  90%|▉| 47/52 [01:13<00:07,  1.56s/it, loss=0.0173, v_num=2, train_loss_step=0.0197, val_loss_step=0.020, val\u001b[A\n",
      "Epoch 22:  92%|▉| 48/52 [01:13<00:06,  1.53s/it, loss=0.0173, v_num=2, train_loss_step=0.0197, val_loss_step=0.020, val\u001b[A\n",
      "Epoch 22:  94%|▉| 49/52 [01:13<00:04,  1.50s/it, loss=0.0173, v_num=2, train_loss_step=0.0197, val_loss_step=0.020, val\u001b[A\n",
      "Epoch 22:  96%|▉| 50/52 [01:13<00:02,  1.47s/it, loss=0.0173, v_num=2, train_loss_step=0.0197, val_loss_step=0.020, val\u001b[A\n",
      "Epoch 22:  98%|▉| 51/52 [01:13<00:01,  1.44s/it, loss=0.0173, v_num=2, train_loss_step=0.0197, val_loss_step=0.020, val\u001b[A\n",
      "Epoch 22: 100%|█| 52/52 [01:13<00:00,  1.41s/it, loss=0.0173, v_num=2, train_loss_step=0.0197, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 23:  81%|▊| 42/52 [01:15<00:18,  1.81s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  83%|▊| 43/52 [01:16<00:15,  1.77s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 23:  85%|▊| 44/52 [01:16<00:13,  1.73s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 23:  87%|▊| 45/52 [01:16<00:11,  1.69s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 23:  88%|▉| 46/52 [01:16<00:09,  1.66s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 23:  90%|▉| 47/52 [01:16<00:08,  1.62s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 23:  92%|▉| 48/52 [01:16<00:06,  1.59s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 23:  94%|▉| 49/52 [01:16<00:04,  1.56s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 23:  96%|▉| 50/52 [01:16<00:03,  1.53s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 23:  98%|▉| 51/52 [01:16<00:01,  1.50s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 23: 100%|█| 52/52 [01:16<00:00,  1.47s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 24:  81%|▊| 42/52 [01:19<00:18,  1.88s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  83%|▊| 43/52 [01:19<00:16,  1.84s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 24:  85%|▊| 44/52 [01:19<00:14,  1.80s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 24:  87%|▊| 45/52 [01:19<00:12,  1.76s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 24:  88%|▉| 46/52 [01:19<00:10,  1.72s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 24:  90%|▉| 47/52 [01:19<00:08,  1.69s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 24:  92%|▉| 48/52 [01:19<00:06,  1.65s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 24:  94%|▉| 49/52 [01:19<00:04,  1.62s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 24:  96%|▉| 50/52 [01:19<00:03,  1.59s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 24:  98%|▉| 51/52 [01:19<00:01,  1.56s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0199, va\u001b[A\n",
      "Epoch 24: 100%|█| 52/52 [01:19<00:00,  1.53s/it, loss=0.0172, v_num=2, train_loss_step=0.0196, val_loss_step=0.0198, va\u001b[A\n",
      "Epoch 25:  81%|▊| 42/52 [01:22<00:19,  1.96s/it, loss=0.0171, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:  83%|▊| 43/52 [01:22<00:17,  1.91s/it, loss=0.0171, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, va\u001b[A\n",
      "Epoch 25:  85%|▊| 44/52 [01:22<00:14,  1.87s/it, loss=0.0171, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, va\u001b[A\n",
      "Epoch 25:  87%|▊| 45/52 [01:22<00:12,  1.83s/it, loss=0.0171, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, va\u001b[A\n",
      "Epoch 25:  88%|▉| 46/52 [01:22<00:10,  1.79s/it, loss=0.0171, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, va\u001b[A\n",
      "Epoch 25:  90%|▉| 47/52 [01:22<00:08,  1.75s/it, loss=0.0171, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, va\u001b[A\n",
      "Epoch 25:  92%|▉| 48/52 [01:22<00:06,  1.72s/it, loss=0.0171, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, va\u001b[A\n",
      "Epoch 25:  94%|▉| 49/52 [01:22<00:05,  1.68s/it, loss=0.0171, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, va\u001b[A\n",
      "Epoch 25:  96%|▉| 50/52 [01:22<00:03,  1.65s/it, loss=0.0171, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, va\u001b[A\n",
      "Epoch 25:  98%|▉| 51/52 [01:22<00:01,  1.62s/it, loss=0.0171, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, va\u001b[A\n",
      "Epoch 25: 100%|█| 52/52 [01:22<00:00,  1.59s/it, loss=0.0171, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, va\u001b[A\n",
      "Epoch 26:  81%|▊| 42/52 [01:25<00:20,  2.03s/it, loss=0.017, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:  83%|▊| 43/52 [01:25<00:17,  1.98s/it, loss=0.017, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, val\u001b[A\n",
      "Epoch 26:  85%|▊| 44/52 [01:25<00:15,  1.94s/it, loss=0.017, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, val\u001b[A\n",
      "Epoch 26:  87%|▊| 45/52 [01:25<00:13,  1.89s/it, loss=0.017, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, val\u001b[A\n",
      "Epoch 26:  88%|▉| 46/52 [01:25<00:11,  1.85s/it, loss=0.017, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, val\u001b[A\n",
      "Epoch 26:  90%|▉| 47/52 [01:25<00:09,  1.82s/it, loss=0.017, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, val\u001b[A\n",
      "Epoch 26:  92%|▉| 48/52 [01:25<00:07,  1.78s/it, loss=0.017, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, val\u001b[A\n",
      "Epoch 26:  94%|▉| 49/52 [01:25<00:05,  1.74s/it, loss=0.017, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, val\u001b[A\n",
      "Epoch 26:  96%|▉| 50/52 [01:25<00:03,  1.71s/it, loss=0.017, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, val\u001b[A\n",
      "Epoch 26:  98%|▉| 51/52 [01:25<00:01,  1.68s/it, loss=0.017, v_num=2, train_loss_step=0.0195, val_loss_step=0.0198, val\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|█| 52/52 [01:25<00:00,  1.65s/it, loss=0.017, v_num=2, train_loss_step=0.0195, val_loss_step=0.0197, val\u001b[A\n",
      "Epoch 27:  81%|▊| 42/52 [01:28<00:21,  2.10s/it, loss=0.017, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:  83%|▊| 43/52 [01:28<00:18,  2.05s/it, loss=0.017, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, val\u001b[A\n",
      "Epoch 27:  85%|▊| 44/52 [01:28<00:16,  2.01s/it, loss=0.017, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, val\u001b[A\n",
      "Epoch 27:  87%|▊| 45/52 [01:28<00:13,  1.96s/it, loss=0.017, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, val\u001b[A\n",
      "Epoch 27:  88%|▉| 46/52 [01:28<00:11,  1.92s/it, loss=0.017, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, val\u001b[A\n",
      "Epoch 27:  90%|▉| 47/52 [01:28<00:09,  1.88s/it, loss=0.017, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, val\u001b[A\n",
      "Epoch 27:  92%|▉| 48/52 [01:28<00:07,  1.84s/it, loss=0.017, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, val\u001b[A\n",
      "Epoch 27:  94%|▉| 49/52 [01:28<00:05,  1.81s/it, loss=0.017, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, val\u001b[A\n",
      "Epoch 27:  96%|▉| 50/52 [01:28<00:03,  1.77s/it, loss=0.017, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, val\u001b[A\n",
      "Epoch 27:  98%|▉| 51/52 [01:28<00:01,  1.74s/it, loss=0.017, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, val\u001b[A\n",
      "Epoch 27: 100%|█| 52/52 [01:28<00:00,  1.71s/it, loss=0.017, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, val\u001b[A\n",
      "Epoch 28:  81%|▊| 42/52 [01:31<00:21,  2.17s/it, loss=0.0169, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:  83%|▊| 43/52 [01:31<00:19,  2.12s/it, loss=0.0169, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, va\u001b[A\n",
      "Epoch 28:  85%|▊| 44/52 [01:31<00:16,  2.07s/it, loss=0.0169, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, va\u001b[A\n",
      "Epoch 28:  87%|▊| 45/52 [01:31<00:14,  2.03s/it, loss=0.0169, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, va\u001b[A\n",
      "Epoch 28:  88%|▉| 46/52 [01:31<00:11,  1.99s/it, loss=0.0169, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, va\u001b[A\n",
      "Epoch 28:  90%|▉| 47/52 [01:31<00:09,  1.95s/it, loss=0.0169, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, va\u001b[A\n",
      "Epoch 28:  92%|▉| 48/52 [01:31<00:07,  1.91s/it, loss=0.0169, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, va\u001b[A\n",
      "Epoch 28:  94%|▉| 49/52 [01:31<00:05,  1.87s/it, loss=0.0169, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, va\u001b[A\n",
      "Epoch 28:  96%|▉| 50/52 [01:31<00:03,  1.83s/it, loss=0.0169, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, va\u001b[A\n",
      "Epoch 28:  98%|▉| 51/52 [01:31<00:01,  1.80s/it, loss=0.0169, v_num=2, train_loss_step=0.0194, val_loss_step=0.0197, va\u001b[A\n",
      "Epoch 28: 100%|█| 52/52 [01:31<00:00,  1.77s/it, loss=0.0169, v_num=2, train_loss_step=0.0194, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 29:  81%|▊| 42/52 [01:34<00:22,  2.24s/it, loss=0.0169, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29:  83%|▊| 43/52 [01:34<00:19,  2.19s/it, loss=0.0169, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 29:  85%|▊| 44/52 [01:34<00:17,  2.15s/it, loss=0.0169, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 29:  87%|▊| 45/52 [01:34<00:14,  2.10s/it, loss=0.0169, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 29:  88%|▉| 46/52 [01:34<00:12,  2.05s/it, loss=0.0169, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 29:  90%|▉| 47/52 [01:34<00:10,  2.01s/it, loss=0.0169, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 29:  92%|▉| 48/52 [01:34<00:07,  1.97s/it, loss=0.0169, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 29:  94%|▉| 49/52 [01:34<00:05,  1.93s/it, loss=0.0169, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 29:  96%|▉| 50/52 [01:34<00:03,  1.89s/it, loss=0.0169, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 29:  98%|▉| 51/52 [01:34<00:01,  1.86s/it, loss=0.0169, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 29: 100%|█| 52/52 [01:34<00:00,  1.82s/it, loss=0.0169, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 30:  81%|▊| 42/52 [01:37<00:23,  2.32s/it, loss=0.0168, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30:  83%|▊| 43/52 [01:37<00:20,  2.26s/it, loss=0.0168, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 30:  85%|▊| 44/52 [01:37<00:17,  2.22s/it, loss=0.0168, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 30:  87%|▊| 45/52 [01:37<00:15,  2.17s/it, loss=0.0168, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 30:  88%|▉| 46/52 [01:37<00:12,  2.12s/it, loss=0.0168, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 30:  90%|▉| 47/52 [01:37<00:10,  2.08s/it, loss=0.0168, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 30:  92%|▉| 48/52 [01:37<00:08,  2.04s/it, loss=0.0168, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 30:  94%|▉| 49/52 [01:37<00:05,  2.00s/it, loss=0.0168, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 30:  96%|▉| 50/52 [01:37<00:03,  1.96s/it, loss=0.0168, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 30:  98%|▉| 51/52 [01:37<00:01,  1.92s/it, loss=0.0168, v_num=2, train_loss_step=0.0193, val_loss_step=0.0196, va\u001b[A\n",
      "Epoch 30: 100%|█| 52/52 [01:37<00:00,  1.88s/it, loss=0.0168, v_num=2, train_loss_step=0.0193, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 31:  81%|▊| 42/52 [01:40<00:23,  2.39s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31:  83%|▊| 43/52 [01:40<00:21,  2.34s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 31:  85%|▊| 44/52 [01:40<00:18,  2.28s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 31:  87%|▊| 45/52 [01:40<00:15,  2.23s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 31:  88%|▉| 46/52 [01:40<00:13,  2.19s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 31:  90%|▉| 47/52 [01:40<00:10,  2.14s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 31:  92%|▉| 48/52 [01:40<00:08,  2.10s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 31:  94%|▉| 49/52 [01:40<00:06,  2.06s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 31:  96%|▉| 50/52 [01:40<00:04,  2.02s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 31:  98%|▉| 51/52 [01:41<00:01,  1.98s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 31: 100%|█| 52/52 [01:41<00:00,  1.94s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 32:  81%|▊| 42/52 [01:43<00:24,  2.46s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32:  83%|▊| 43/52 [01:43<00:21,  2.41s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32:  85%|▊| 44/52 [01:43<00:18,  2.35s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 32:  87%|▊| 45/52 [01:43<00:16,  2.30s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 32:  88%|▉| 46/52 [01:43<00:13,  2.25s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 32:  90%|▉| 47/52 [01:43<00:11,  2.21s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 32:  92%|▉| 48/52 [01:43<00:08,  2.16s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 32:  94%|▉| 49/52 [01:43<00:06,  2.12s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 32:  96%|▉| 50/52 [01:43<00:04,  2.08s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 32:  98%|▉| 51/52 [01:43<00:02,  2.04s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 32: 100%|█| 52/52 [01:43<00:00,  2.00s/it, loss=0.0168, v_num=2, train_loss_step=0.0192, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 33:  81%|▊| 42/52 [01:46<00:25,  2.53s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0195, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33:  83%|▊| 43/52 [01:46<00:22,  2.48s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 33:  85%|▊| 44/52 [01:46<00:19,  2.42s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 33:  87%|▊| 45/52 [01:46<00:16,  2.37s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 33:  88%|▉| 46/52 [01:46<00:13,  2.32s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 33:  90%|▉| 47/52 [01:46<00:11,  2.27s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 33:  92%|▉| 48/52 [01:46<00:08,  2.23s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 33:  94%|▉| 49/52 [01:46<00:06,  2.18s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 33:  96%|▉| 50/52 [01:47<00:04,  2.14s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 33:  98%|▉| 51/52 [01:47<00:02,  2.10s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0195, va\u001b[A\n",
      "Epoch 33: 100%|█| 52/52 [01:47<00:00,  2.06s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 34:  81%|▊| 42/52 [01:49<00:26,  2.61s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:  83%|▊| 43/52 [01:49<00:22,  2.55s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 34:  85%|▊| 44/52 [01:49<00:19,  2.49s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 34:  87%|▊| 45/52 [01:49<00:17,  2.44s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 34:  88%|▉| 46/52 [01:49<00:14,  2.39s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 34:  90%|▉| 47/52 [01:49<00:11,  2.34s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 34:  92%|▉| 48/52 [01:49<00:09,  2.29s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 34:  94%|▉| 49/52 [01:49<00:06,  2.24s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 34:  96%|▉| 50/52 [01:49<00:04,  2.20s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 34:  98%|▉| 51/52 [01:49<00:02,  2.16s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 34: 100%|█| 52/52 [01:50<00:00,  2.12s/it, loss=0.0167, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 35:  81%|▊| 42/52 [01:52<00:26,  2.68s/it, loss=0.0166, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:  83%|▊| 43/52 [01:52<00:23,  2.62s/it, loss=0.0166, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 35:  85%|▊| 44/52 [01:52<00:20,  2.56s/it, loss=0.0166, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 35:  87%|▊| 45/52 [01:52<00:17,  2.51s/it, loss=0.0166, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 35:  88%|▉| 46/52 [01:52<00:14,  2.45s/it, loss=0.0166, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 35:  90%|▉| 47/52 [01:52<00:12,  2.40s/it, loss=0.0166, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 35:  92%|▉| 48/52 [01:52<00:09,  2.35s/it, loss=0.0166, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 35:  94%|▉| 49/52 [01:53<00:06,  2.31s/it, loss=0.0166, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 35:  96%|▉| 50/52 [01:53<00:04,  2.26s/it, loss=0.0166, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 35:  98%|▉| 51/52 [01:53<00:02,  2.22s/it, loss=0.0166, v_num=2, train_loss_step=0.0191, val_loss_step=0.0194, va\u001b[A\n",
      "Epoch 35: 100%|█| 52/52 [01:53<00:00,  2.18s/it, loss=0.0166, v_num=2, train_loss_step=0.0191, val_loss_step=0.0193, va\u001b[A\n",
      "Epoch 36:  81%|▊| 42/52 [01:55<00:27,  2.75s/it, loss=0.0166, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:  83%|▊| 43/52 [01:55<00:24,  2.69s/it, loss=0.0166, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 36:  85%|▊| 44/52 [01:55<00:21,  2.63s/it, loss=0.0166, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 36:  87%|▊| 45/52 [01:55<00:18,  2.57s/it, loss=0.0166, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 36:  88%|▉| 46/52 [01:55<00:15,  2.52s/it, loss=0.0166, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 36:  90%|▉| 47/52 [01:55<00:12,  2.47s/it, loss=0.0166, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 36:  92%|▉| 48/52 [01:55<00:09,  2.42s/it, loss=0.0166, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 36:  94%|▉| 49/52 [01:55<00:07,  2.37s/it, loss=0.0166, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 36:  96%|▉| 50/52 [01:56<00:04,  2.32s/it, loss=0.0166, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 36:  98%|▉| 51/52 [01:56<00:02,  2.28s/it, loss=0.0166, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 36: 100%|█| 52/52 [01:56<00:00,  2.24s/it, loss=0.0166, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 37:  81%|▊| 42/52 [01:58<00:28,  2.83s/it, loss=0.0165, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37:  83%|▊| 43/52 [01:58<00:24,  2.76s/it, loss=0.0165, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 37:  85%|▊| 44/52 [01:58<00:21,  2.70s/it, loss=0.0165, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 37:  87%|▊| 45/52 [01:58<00:18,  2.64s/it, loss=0.0165, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 37:  88%|▉| 46/52 [01:58<00:15,  2.58s/it, loss=0.0165, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 37:  90%|▉| 47/52 [01:58<00:12,  2.53s/it, loss=0.0165, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 37:  92%|▉| 48/52 [01:58<00:09,  2.48s/it, loss=0.0165, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37:  94%|▉| 49/52 [01:59<00:07,  2.43s/it, loss=0.0165, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 37:  96%|▉| 50/52 [01:59<00:04,  2.38s/it, loss=0.0165, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 37:  98%|▉| 51/52 [01:59<00:02,  2.34s/it, loss=0.0165, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 37: 100%|█| 52/52 [01:59<00:00,  2.29s/it, loss=0.0165, v_num=2, train_loss_step=0.019, val_loss_step=0.0193, val\u001b[A\n",
      "Epoch 38:  81%|▊| 42/52 [02:01<00:28,  2.89s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0193, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38:  83%|▊| 43/52 [02:01<00:25,  2.83s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0193, va\u001b[A\n",
      "Epoch 38:  85%|▊| 44/52 [02:01<00:22,  2.76s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0193, va\u001b[A\n",
      "Epoch 38:  87%|▊| 45/52 [02:01<00:18,  2.70s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0193, va\u001b[A\n",
      "Epoch 38:  88%|▉| 46/52 [02:01<00:15,  2.65s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0193, va\u001b[A\n",
      "Epoch 38:  90%|▉| 47/52 [02:01<00:12,  2.59s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0193, va\u001b[A\n",
      "Epoch 38:  92%|▉| 48/52 [02:01<00:10,  2.54s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0193, va\u001b[A\n",
      "Epoch 38:  94%|▉| 49/52 [02:02<00:07,  2.49s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0193, va\u001b[A\n",
      "Epoch 38:  96%|▉| 50/52 [02:02<00:04,  2.44s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0193, va\u001b[A\n",
      "Epoch 38:  98%|▉| 51/52 [02:02<00:02,  2.40s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0193, va\u001b[A\n",
      "Epoch 38: 100%|█| 52/52 [02:02<00:00,  2.35s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 39:  81%|▊| 42/52 [02:04<00:29,  2.97s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39:  83%|▊| 43/52 [02:04<00:26,  2.90s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 39:  85%|▊| 44/52 [02:04<00:22,  2.83s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 39:  87%|▊| 45/52 [02:04<00:19,  2.77s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 39:  88%|▉| 46/52 [02:04<00:16,  2.71s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 39:  90%|▉| 47/52 [02:04<00:13,  2.65s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 39:  92%|▉| 48/52 [02:04<00:10,  2.60s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 39:  94%|▉| 49/52 [02:04<00:07,  2.55s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 39:  96%|▉| 50/52 [02:04<00:04,  2.50s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 39:  98%|▉| 51/52 [02:04<00:02,  2.45s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 39: 100%|█| 52/52 [02:04<00:00,  2.40s/it, loss=0.0165, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 40:  81%|▊| 42/52 [02:07<00:30,  3.03s/it, loss=0.0164, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 40:  83%|▊| 43/52 [02:07<00:26,  2.97s/it, loss=0.0164, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 40:  85%|▊| 44/52 [02:07<00:23,  2.90s/it, loss=0.0164, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 40:  87%|▊| 45/52 [02:07<00:19,  2.84s/it, loss=0.0164, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 40:  88%|▉| 46/52 [02:07<00:16,  2.78s/it, loss=0.0164, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 40:  90%|▉| 47/52 [02:07<00:13,  2.72s/it, loss=0.0164, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 40:  92%|▉| 48/52 [02:07<00:10,  2.66s/it, loss=0.0164, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 40:  94%|▉| 49/52 [02:07<00:07,  2.61s/it, loss=0.0164, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 40:  96%|▉| 50/52 [02:07<00:05,  2.56s/it, loss=0.0164, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 40:  98%|▉| 51/52 [02:08<00:02,  2.51s/it, loss=0.0164, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 40: 100%|█| 52/52 [02:08<00:00,  2.46s/it, loss=0.0164, v_num=2, train_loss_step=0.0189, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 41:  81%|▊| 42/52 [02:10<00:31,  3.11s/it, loss=0.0164, v_num=2, train_loss_step=0.0188, val_loss_step=0.0192, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 41:  83%|▊| 43/52 [02:10<00:27,  3.04s/it, loss=0.0164, v_num=2, train_loss_step=0.0188, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 41:  85%|▊| 44/52 [02:10<00:23,  2.97s/it, loss=0.0164, v_num=2, train_loss_step=0.0188, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 41:  87%|▊| 45/52 [02:10<00:20,  2.90s/it, loss=0.0164, v_num=2, train_loss_step=0.0188, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 41:  88%|▉| 46/52 [02:10<00:17,  2.84s/it, loss=0.0164, v_num=2, train_loss_step=0.0188, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 41:  90%|▉| 47/52 [02:10<00:13,  2.78s/it, loss=0.0164, v_num=2, train_loss_step=0.0188, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 41:  92%|▉| 48/52 [02:10<00:10,  2.72s/it, loss=0.0164, v_num=2, train_loss_step=0.0188, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 41:  94%|▉| 49/52 [02:10<00:08,  2.67s/it, loss=0.0164, v_num=2, train_loss_step=0.0188, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 41:  96%|▉| 50/52 [02:10<00:05,  2.62s/it, loss=0.0164, v_num=2, train_loss_step=0.0188, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 41:  98%|▉| 51/52 [02:10<00:02,  2.57s/it, loss=0.0164, v_num=2, train_loss_step=0.0188, val_loss_step=0.0192, va\u001b[A\n",
      "Epoch 41: 100%|█| 52/52 [02:11<00:00,  2.52s/it, loss=0.0164, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 42:  81%|▊| 42/52 [02:13<00:31,  3.18s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 42:  83%|▊| 43/52 [02:13<00:27,  3.11s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 42:  85%|▊| 44/52 [02:13<00:24,  3.04s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 42:  87%|▊| 45/52 [02:13<00:20,  2.97s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 42:  88%|▉| 46/52 [02:13<00:17,  2.91s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 42:  90%|▉| 47/52 [02:13<00:14,  2.85s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 42:  92%|▉| 48/52 [02:13<00:11,  2.79s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 42:  94%|▉| 49/52 [02:13<00:08,  2.73s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 42:  96%|▉| 50/52 [02:13<00:05,  2.68s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 42:  98%|▉| 51/52 [02:13<00:02,  2.63s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 42: 100%|█| 52/52 [02:14<00:00,  2.58s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 43:  81%|▊| 42/52 [02:16<00:32,  3.25s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 43:  83%|▊| 43/52 [02:16<00:28,  3.17s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 43:  85%|▊| 44/52 [02:16<00:24,  3.10s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 43:  87%|▊| 45/52 [02:16<00:21,  3.04s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 43:  88%|▉| 46/52 [02:16<00:17,  2.97s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 43:  90%|▉| 47/52 [02:16<00:14,  2.91s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 43:  92%|▉| 48/52 [02:16<00:11,  2.85s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 43:  94%|▉| 49/52 [02:16<00:08,  2.80s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 43:  96%|▉| 50/52 [02:17<00:05,  2.74s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 43:  98%|▉| 51/52 [02:17<00:02,  2.69s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 43: 100%|█| 52/52 [02:17<00:00,  2.64s/it, loss=0.0163, v_num=2, train_loss_step=0.0188, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 44:  81%|▊| 42/52 [02:19<00:33,  3.32s/it, loss=0.0163, v_num=2, train_loss_step=0.0187, val_loss_step=0.0191, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 44:  83%|▊| 43/52 [02:19<00:29,  3.25s/it, loss=0.0163, v_num=2, train_loss_step=0.0187, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 44:  85%|▊| 44/52 [02:19<00:25,  3.17s/it, loss=0.0163, v_num=2, train_loss_step=0.0187, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 44:  87%|▊| 45/52 [02:19<00:21,  3.10s/it, loss=0.0163, v_num=2, train_loss_step=0.0187, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 44:  88%|▉| 46/52 [02:19<00:18,  3.04s/it, loss=0.0163, v_num=2, train_loss_step=0.0187, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 44:  90%|▉| 47/52 [02:19<00:14,  2.97s/it, loss=0.0163, v_num=2, train_loss_step=0.0187, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 44:  92%|▉| 48/52 [02:19<00:11,  2.91s/it, loss=0.0163, v_num=2, train_loss_step=0.0187, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 44:  94%|▉| 49/52 [02:19<00:08,  2.85s/it, loss=0.0163, v_num=2, train_loss_step=0.0187, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 44:  96%|▉| 50/52 [02:19<00:05,  2.80s/it, loss=0.0163, v_num=2, train_loss_step=0.0187, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 44:  98%|▉| 51/52 [02:19<00:02,  2.74s/it, loss=0.0163, v_num=2, train_loss_step=0.0187, val_loss_step=0.0191, va\u001b[A\n",
      "Epoch 44: 100%|█| 52/52 [02:20<00:00,  2.69s/it, loss=0.0163, v_num=2, train_loss_step=0.0187, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 45:  81%|▊| 42/52 [02:22<00:33,  3.40s/it, loss=0.0162, v_num=2, train_loss_step=0.0187, val_loss_step=0.019, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 45:  83%|▊| 43/52 [02:22<00:29,  3.32s/it, loss=0.0162, v_num=2, train_loss_step=0.0187, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 45:  85%|▊| 44/52 [02:22<00:25,  3.24s/it, loss=0.0162, v_num=2, train_loss_step=0.0187, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 45:  87%|▊| 45/52 [02:22<00:22,  3.17s/it, loss=0.0162, v_num=2, train_loss_step=0.0187, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 45:  88%|▉| 46/52 [02:22<00:18,  3.11s/it, loss=0.0162, v_num=2, train_loss_step=0.0187, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 45:  90%|▉| 47/52 [02:22<00:15,  3.04s/it, loss=0.0162, v_num=2, train_loss_step=0.0187, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 45:  92%|▉| 48/52 [02:22<00:11,  2.98s/it, loss=0.0162, v_num=2, train_loss_step=0.0187, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 45:  94%|▉| 49/52 [02:22<00:08,  2.92s/it, loss=0.0162, v_num=2, train_loss_step=0.0187, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 45:  96%|▉| 50/52 [02:23<00:05,  2.86s/it, loss=0.0162, v_num=2, train_loss_step=0.0187, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 45:  98%|▉| 51/52 [02:23<00:02,  2.81s/it, loss=0.0162, v_num=2, train_loss_step=0.0187, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 45: 100%|█| 52/52 [02:23<00:00,  2.75s/it, loss=0.0162, v_num=2, train_loss_step=0.0187, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 46:  81%|▊| 42/52 [02:25<00:34,  3.47s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 46:  83%|▊| 43/52 [02:25<00:30,  3.39s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 46:  85%|▊| 44/52 [02:25<00:26,  3.31s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 46:  87%|▊| 45/52 [02:25<00:22,  3.24s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 46:  88%|▉| 46/52 [02:25<00:19,  3.17s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 46:  90%|▉| 47/52 [02:25<00:15,  3.10s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 46:  92%|▉| 48/52 [02:25<00:12,  3.04s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 46:  94%|▉| 49/52 [02:25<00:08,  2.98s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 46:  96%|▉| 50/52 [02:25<00:05,  2.92s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 46:  98%|▉| 51/52 [02:26<00:02,  2.87s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 46: 100%|█| 52/52 [02:26<00:00,  2.81s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 47:  81%|▊| 42/52 [02:28<00:35,  3.54s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 47:  83%|▊| 43/52 [02:28<00:31,  3.46s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 47:  85%|▊| 44/52 [02:28<00:27,  3.38s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 47:  87%|▊| 45/52 [02:28<00:23,  3.31s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 47:  88%|▉| 46/52 [02:28<00:19,  3.24s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 47:  90%|▉| 47/52 [02:28<00:15,  3.17s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 47:  92%|▉| 48/52 [02:28<00:12,  3.10s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 47:  94%|▉| 49/52 [02:28<00:09,  3.04s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 47:  96%|▉| 50/52 [02:29<00:05,  2.98s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 47:  98%|▉| 51/52 [02:29<00:02,  2.92s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.019, val\u001b[A\n",
      "Epoch 47: 100%|█| 52/52 [02:29<00:00,  2.87s/it, loss=0.0162, v_num=2, train_loss_step=0.0186, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 48:  81%|▊| 42/52 [02:31<00:36,  3.61s/it, loss=0.0161, v_num=2, train_loss_step=0.0186, val_loss_step=0.0189, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 48:  83%|▊| 43/52 [02:31<00:31,  3.53s/it, loss=0.0161, v_num=2, train_loss_step=0.0186, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 48:  85%|▊| 44/52 [02:31<00:27,  3.45s/it, loss=0.0161, v_num=2, train_loss_step=0.0186, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 48:  87%|▊| 45/52 [02:31<00:23,  3.37s/it, loss=0.0161, v_num=2, train_loss_step=0.0186, val_loss_step=0.0189, va\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48:  88%|▉| 46/52 [02:31<00:19,  3.30s/it, loss=0.0161, v_num=2, train_loss_step=0.0186, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 48:  90%|▉| 47/52 [02:31<00:16,  3.23s/it, loss=0.0161, v_num=2, train_loss_step=0.0186, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 48:  92%|▉| 48/52 [02:32<00:12,  3.17s/it, loss=0.0161, v_num=2, train_loss_step=0.0186, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 48:  94%|▉| 49/52 [02:32<00:09,  3.10s/it, loss=0.0161, v_num=2, train_loss_step=0.0186, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 48:  96%|▉| 50/52 [02:32<00:06,  3.04s/it, loss=0.0161, v_num=2, train_loss_step=0.0186, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 48:  98%|▉| 51/52 [02:32<00:02,  2.98s/it, loss=0.0161, v_num=2, train_loss_step=0.0186, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 48: 100%|█| 52/52 [02:32<00:00,  2.93s/it, loss=0.0161, v_num=2, train_loss_step=0.0186, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 49:  81%|▊| 42/52 [02:34<00:36,  3.68s/it, loss=0.0161, v_num=2, train_loss_step=0.0185, val_loss_step=0.0189, va\u001b[A\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                                  | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49:  83%|▊| 43/52 [02:34<00:32,  3.60s/it, loss=0.0161, v_num=2, train_loss_step=0.0185, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 49:  85%|▊| 44/52 [02:34<00:28,  3.52s/it, loss=0.0161, v_num=2, train_loss_step=0.0185, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 49:  87%|▊| 45/52 [02:34<00:24,  3.44s/it, loss=0.0161, v_num=2, train_loss_step=0.0185, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 49:  88%|▉| 46/52 [02:34<00:20,  3.37s/it, loss=0.0161, v_num=2, train_loss_step=0.0185, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 49:  90%|▉| 47/52 [02:34<00:16,  3.30s/it, loss=0.0161, v_num=2, train_loss_step=0.0185, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 49:  92%|▉| 48/52 [02:34<00:12,  3.23s/it, loss=0.0161, v_num=2, train_loss_step=0.0185, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 49:  94%|▉| 49/52 [02:35<00:09,  3.16s/it, loss=0.0161, v_num=2, train_loss_step=0.0185, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 49:  96%|▉| 50/52 [02:35<00:06,  3.10s/it, loss=0.0161, v_num=2, train_loss_step=0.0185, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 49:  98%|▉| 51/52 [02:35<00:03,  3.04s/it, loss=0.0161, v_num=2, train_loss_step=0.0185, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 49: 100%|█| 52/52 [02:35<00:00,  2.98s/it, loss=0.0161, v_num=2, train_loss_step=0.0185, val_loss_step=0.0189, va\u001b[A\n",
      "Epoch 49: 100%|█| 52/52 [02:35<00:00,  2.98s/it, loss=0.0161, v_num=2, train_loss_step=0.0185, val_loss_step=0.0189, va\u001b[A\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(checkpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model\n",
    "\n",
    "**After** training and tuning the model, we can test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer.test(model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "A list of some things that are still to do.\n",
    "Not a complete list.\n",
    "\n",
    "- [x] Implement Preprocessing\n",
    "- [x] Implement Data Preparation\n",
    "- [x] Implement Model basic structure\n",
    "- [x] Set up basic training for model\n",
    "- [ ] Implement cross validation\n",
    "- [ ] Implement hyper parameter tuning\n",
    "- [ ] ...\n",
    "- [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.8042], dtype=torch.float64, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor(all_temp_train_dataset[0]['distances']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5783409394414765"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_temp_train_dataset[0]['speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
